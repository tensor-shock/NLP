{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rajarshidas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "for i in range (1,2):\n",
    "    filename='Harry_Potter_Text/'+'Book'+str(i)+'.txt'\n",
    "    with open(filename) as f:\n",
    "        Lines = f.readlines()\n",
    "        # book=\"\"\n",
    "        for lin in Lines:\n",
    "            if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "                if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                    text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "sentences=[]\n",
    "sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    # if not li[-1].isalnum():\n",
    "    #     li=li[:-1]\n",
    "    # li= '<s> '+li+' <e>'\n",
    "    sentences.append(li)\n",
    "    sentencewise_tokens.append(word_tokenize(li))\n",
    "tokens=word_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5030"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101222"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5030"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentencewise_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tokens=[]\n",
    "for token in tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        final_tokens.append(token.strip('.'))\n",
    "tokens=final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80585"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21079\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value of m in problem statement/ range of n in n-gram\n",
    "n_limit=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 21079\n",
      "2 277884\n",
      "3 642415\n",
      "4 835723\n",
      "5 896438\n"
     ]
    }
   ],
   "source": [
    "ngrams=[]\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams.append(d)\n",
    "for n in range (1,n_limit+1):\n",
    "    for i in range(len(tokens)):\n",
    "        if i+n>len(tokens):\n",
    "            break\n",
    "        lis=[]\n",
    "        for j in range(i,i+n):\n",
    "            lis.append(tokens[j])\n",
    "        lis=tuple(lis)\n",
    "        if lis not in ngrams[n-1]:\n",
    "            ngrams[n-1][lis] = 1\n",
    "        else : \n",
    "            ngrams[n-1][lis] += 1\n",
    "    ngrams[n-1]=dict(sorted(ngrams[n-1].items(), key=lambda item: -item[1]))\n",
    "    print(n,len(ngrams[n-1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams[4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTENCE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n(n,a,line,word_limit):\n",
    "    if word_limit==0:\n",
    "        print(line)\n",
    "        return line\n",
    "    sz=len(a)\n",
    "    if sz==0 or n==1:\n",
    "        word=next(iter(ngrams[0]))[0]#first key\n",
    "        a.append(word)\n",
    "        line=line+' '+word\n",
    "        # print(line)\n",
    "        get_n(n,a,line,word_limit-1)\n",
    "    elif sz<n-1:\n",
    "        found = False\n",
    "        for key in ngrams[sz]:\n",
    "            lis=list(key)\n",
    "            last_word=lis[-1]\n",
    "            lis=lis[:-1]\n",
    "            if lis==a:\n",
    "                line=line+' '+last_word\n",
    "                # a=a[1:]\n",
    "                a.append(last_word)\n",
    "                found=True\n",
    "                break\n",
    "        if found :\n",
    "            # print(line)\n",
    "            get_n(n,a,line,word_limit-1)\n",
    "        else : \n",
    "            print('Cant find')\n",
    "    elif sz==n-1:\n",
    "        found = False\n",
    "        for key in ngrams[n-1]:\n",
    "            lis=list(key)\n",
    "            last_word=lis[-1]\n",
    "            lis=lis[:-1]\n",
    "            if lis==a:\n",
    "                line=line+' '+last_word\n",
    "                a=a[1:]\n",
    "                a.append(last_word)\n",
    "                found=True\n",
    "                break\n",
    "        if found :\n",
    "            # print(line)\n",
    "            get_n(n,a,line,word_limit-1)\n",
    "        else : \n",
    "            print('Cant find')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(n,word_limit):\n",
    "    prev_tokens=[]\n",
    "    sentence=\"\"\n",
    "    line=get_n(n,prev_tokens,sentence,word_limit)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic harry pulled the door open and they ran inside hermione granger was shrinking against the wall opposite looking as if she was about to faint the troll was advancing on her knocking the sinks off the walls as it went confuse it harry said desperately to ron and seizing a tap he threw it as hard as he could into the kitchen harry hurried into the living room in time to catch the last report on the evening news and finally bird-watchers everywhere have reported that the nation s owls\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "filename='Harry_Potter_Text/'+'Book7.txt'\n",
    "with open(filename) as f:\n",
    "    Lines = f.readlines()\n",
    "    # book=\"\"\n",
    "    for lin in Lines:\n",
    "        if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "            if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "test_sentences=[]\n",
    "test_sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    # if not li[-1].isalnum():\n",
    "    #     li=li[:-1]\n",
    "    # li= '<s> '+li+' <e>'\n",
    "    test_sentences.append(li)\n",
    "    test_sentencewise_tokens.append(word_tokenize(li))\n",
    "test_tokens=word_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11138"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256058"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        test_final_tokens.append(token.strip('.'))\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204766"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vocab=set(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11449"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OOV words\n",
    "len(test_vocab.difference(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_vocab.difference(vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and the door and the door and the\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21079"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # print(sz)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            ratio=ngrams[0][tup]/len(tokens)\n",
    "            # print(ratio)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            ratio=ngrams[sz-1][tup1]/ngrams[sz-2][tup2]\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.579554625674844\n"
     ]
    }
   ],
   "source": [
    "s='the door and the door and the door and the'\n",
    "print(log_perp(2,s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOOTHING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp1(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # print(sz)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                ratio=(ngrams[0][tup]+1)/(len(tokens)+len(vocab))\n",
    "            else:\n",
    "                ratio=(1)/(len(tokens)+len(vocab))\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                ratio=(ngrams[sz-1][tup1]+1)/(ngrams[sz-2][tup2]+len(ngrams[sz-2]))\n",
    "            elif tup2 in ngrams[sz-2]:\n",
    "                ratio=1/(ngrams[sz-2][tup2]+len(ngrams[sz-2]))\n",
    "            else:\n",
    "                #ERROR WARNING\n",
    "                ratio=1/len(ngrams[sz-2])\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with add-1 smoothing is 15.077224482717945\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with add-1 smoothing is',log_perp1(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOD TURING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_total=[] #holds total number of n gram tuples per n\n",
    "ngrams_freq=[]  #holds dictionary of frequency and count per n\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams_freq.append(d)\n",
    "for n in range (n_limit):\n",
    "    sum=0\n",
    "    for val in ngrams[n].values():\n",
    "        # print(val,n)\n",
    "        if val in ngrams_freq[n]:\n",
    "            ngrams_freq[n][val]=ngrams_freq[n][val]+1\n",
    "        else:\n",
    "            ngrams_freq[n][val]=1\n",
    "        sum+=val\n",
    "    ngrams_total.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[920732, 920731, 920730, 920729, 920728]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_freq[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp2(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # print(sz)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                freq=ngrams[0][tup]\n",
    "                if freq+1 in ngrams_freq[0]:\n",
    "                    ratio=(freq+1)*ngrams_freq[0][freq+1]/(ngrams_freq[0][freq]*ngrams_total[0])\n",
    "                else:\n",
    "                    ratio=(freq+1)/(ngrams_freq[0][freq]*ngrams_total[0])\n",
    "            else:\n",
    "                if 1 in ngrams_freq[0]:\n",
    "                    ratio=ngrams_freq[0][1]/len(tokens)\n",
    "                else :\n",
    "                    ratio=1/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                freq=ngrams[sz-1][tup1]\n",
    "                if freq+1 in ngrams_freq[sz-1]:\n",
    "                    ratio=(freq+1)*ngrams_freq[sz-1][freq+1]/(ngrams_freq[sz-1][freq]*ngrams_total[sz-1])\n",
    "                else:\n",
    "                    ratio=(freq+1)/(ngrams_freq[sz-1][freq]*ngrams_total[sz-1])\n",
    "            else:\n",
    "                if 1 in ngrams_freq[sz-1]:\n",
    "                    ratio=ngrams_freq[sz-1][1]/ngrams_total[sz-1]\n",
    "                else:\n",
    "                    ratio=1/ngrams_total[sz-1]\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with good turing smoothing is 18.961096391546445\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with good turing smoothing is',log_perp2(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp3(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # print(sz)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            ratio=ngrams[0][tup]/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                \n",
    "                lis=lis[:-1]\n",
    "                tup2=tuple(lis)\n",
    "                ratio=ngrams[sz-1][tup1]/ngrams[sz-2][tup2]\n",
    "                sum+=math.log2(ratio)\n",
    "            else :\n",
    "                lis=lis[1:]\n",
    "                snew=' '.join(lis)\n",
    "                back=-1*log_perp3(n-1,snew)*len(lis)\n",
    "                # print(snew,back)\n",
    "                sum+=back\n",
    "                sum+=math.log2(0.4)\n",
    "                \n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4733372813656676\n",
      "17.00506684057854\n",
      "11.400166108415785\n",
      "4.4733372813656676\n"
     ]
    }
   ],
   "source": [
    "print(log_perp(1,'the'))\n",
    "print(log_perp(1,'animagi'))\n",
    "print(log_perp3(2,'animagi the'))\n",
    "print(log_perp3(1,'the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_perp(2,'animagi the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with backoff smoothing is 1.9812421762636143\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with backoff smoothing is',log_perp3(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity with backoff smoothing is 7.710051297553377\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their ministry'\n",
    "n_val=5\n",
    "# print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with backoff smoothing is',log_perp3(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNESSER-NEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_unique_prefix=[]     # for each n gram model contains number of unique w_i-1 for each w_i as key\n",
    "ngrams_unique_suffix=[]     # for each n gram model contains number of unique w_i for each w_i-1 as key\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams_unique_prefix.append(d)\n",
    "    ngrams_unique_suffix.append(d)\n",
    "for n in range (1,n_limit):\n",
    "    for key in ngrams[n]:\n",
    "        lis=list(key)\n",
    "        lastword=lis[-1]\n",
    "        lis=tuple(lis[:-1])\n",
    "        if lastword in ngrams_unique_prefix[n]:\n",
    "            ngrams_unique_prefix[n][lastword]=ngrams_unique_prefix[n][lastword]+1\n",
    "        else:\n",
    "            ngrams_unique_prefix[n][lastword]=1\n",
    "        if lis in ngrams_unique_suffix[n]:\n",
    "            ngrams_unique_suffix[n][lis]=ngrams_unique_suffix[n][lis]+1\n",
    "        else:\n",
    "            ngrams_unique_suffix[n][lis]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp4(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # Absolute discounting\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                ratio=(ngrams[0][tup]-0.75)/len(tokens)\n",
    "            else :\n",
    "                ratio = 1/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "\n",
    "            # CONTINUATION PROBABILITY\n",
    "            lastword=lis[-1]\n",
    "            # pcont_ratio=0\n",
    "            pcont_ratio=ngrams_unique_prefix[sz-1][lastword]/len(ngrams[sz-1])\n",
    "\n",
    "            # LAMBDA\n",
    "            if tup2 in ngrams_unique_suffix[sz-1]:\n",
    "                lambdamult=0.75*ngrams_unique_suffix[sz-1][tup2]/ngrams[sz-2][tup2]\n",
    "            else: \n",
    "                lambdamult=1\n",
    "            # lambdamult=1\n",
    "\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                # add-1 smoothing\n",
    "                # ratio=(max(ngrams[sz-1][tup1]-0.75,0)+1)/(ngrams[sz-2][tup2]+ngrams[sz-2])\n",
    "                ratio=max(ngrams[sz-1][tup1]-0.75,0)/(ngrams[sz-2][tup2])\n",
    "                sum+=math.log2(ratio+lambdamult*pcont_ratio)\n",
    "            else :\n",
    "                ratio=1/len(ngrams[sz-2])\n",
    "                sum+=math.log2(ratio+lambdamult*pcont_ratio)\n",
    "\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with KN is 2.88767992295894\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with KN is',log_perp4(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERPOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp5(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        \n",
    "        ratio_lis=[]\n",
    "        while True:\n",
    "            tup1=tuple(lis)\n",
    "            if len(lis)==1:\n",
    "                ratio=ngrams[0][tup1]/len(tokens)\n",
    "                ratio_lis.append(ratio)\n",
    "                break\n",
    "            elif tup1 in ngrams[len(lis)-1]:\n",
    "                lis2=lis[:-1]\n",
    "                tup2=tuple(lis2)\n",
    "                ratio=ngrams[len(lis)-1][tup1]/ngrams[len(lis)-2][tup2]\n",
    "                ratio_lis.append(ratio)\n",
    "            lis=lis[1:]\n",
    "        sz=len(ratio_lis)\n",
    "        final_ratio=0\n",
    "        for ratio in ratio_lis:\n",
    "            final_ratio+=ratio*(1/sz)\n",
    "        sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with interpolation is 9.524394374722691\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with interpolation is',log_perp5(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERFORMANCE ON TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "filename='Harry_Potter_Text/'+'Book7.txt'\n",
    "with open(filename) as f:\n",
    "    Lines = f.readlines()\n",
    "    # book=\"\"\n",
    "    for lin in Lines:\n",
    "        if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "            if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "test_sentences=[]\n",
    "test_sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    # if not li[-1].isalnum():\n",
    "    #     li=li[:-1]\n",
    "    # li= '<s> '+li+' <e>'\n",
    "    test_sentences.append(li)\n",
    "    test_sentencewise_tokens.append(word_tokenize(li))\n",
    "test_tokens=word_tokenize(text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        test_final_tokens.append(token.strip('.'))\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204766"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if token in tokens:\n",
    "        test_final_tokens.append(token)\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185632"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_book=' '.join(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity by add-1 is 19.623598669029754\n",
      "Log2-perplexity by GT is 0.7538775399073951\n",
      "Log2-perplexity by backoff is 46.44231070423704\n",
      "Log2-perplexity by KN is 8.906824640255648\n",
      "Log2-perplexity by interpolation is 5.533226856638685\n"
     ]
    }
   ],
   "source": [
    "n_val=5\n",
    "print('Log2-perplexity by add-1 is',log_perp1(n_val,test_book))\n",
    "print('Log2-perplexity by GT is',log_perp2(n_val,test_book))\n",
    "print('Log2-perplexity by backoff is',log_perp3(n_val,test_book))\n",
    "print('Log2-perplexity by KN is',log_perp4(n_val,test_book))\n",
    "print('Log2-perplexity by interpolation is',log_perp5(n_val,test_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a9832322fafd2730dc149af687337c0a09b45fcc0b3b65c4fba6625a2f98152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
