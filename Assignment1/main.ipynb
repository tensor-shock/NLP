{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rajarshidas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "for i in range (1,7):\n",
    "    filename='Harry_Potter_Text/'+'Book'+str(i)+'.txt'\n",
    "    with open(filename) as f:\n",
    "        Lines = f.readlines()\n",
    "        # book=\"\"\n",
    "        for lin in Lines:\n",
    "            if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "                if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                    text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "sentences=[]\n",
    "sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    sentences.append(li)\n",
    "    sentencewise_tokens.append(word_tokenize(li))\n",
    "tokens=word_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51670"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155432"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51670"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentencewise_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tokens=[]\n",
    "for token in tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        final_tokens.append(token.strip('.'))\n",
    "tokens=final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920732"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21079\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_book=' '.join(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value of m in problem statement/ range of n in n-gram\n",
    "n_limit=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 21079\n",
      "2 277884\n",
      "3 642415\n",
      "4 835723\n",
      "5 896438\n"
     ]
    }
   ],
   "source": [
    "ngrams=[]\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams.append(d)\n",
    "for n in range (1,n_limit+1):\n",
    "    for i in range(len(tokens)):\n",
    "        if i+n>len(tokens):\n",
    "            break\n",
    "        lis=[]\n",
    "        for j in range(i,i+n):\n",
    "            lis.append(tokens[j])\n",
    "        lis=tuple(lis)\n",
    "        if lis not in ngrams[n-1]:\n",
    "            ngrams[n-1][lis] = 1\n",
    "        else : \n",
    "            ngrams[n-1][lis] += 1\n",
    "    ngrams[n-1]=dict(sorted(ngrams[n-1].items(), key=lambda item: -item[1]))\n",
    "    print(n,len(ngrams[n-1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams[4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTENCE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n(n,a,line,word_limit):\n",
    "    if word_limit==0:\n",
    "        print(line)\n",
    "        return line\n",
    "    sz=len(a)\n",
    "    if sz==0 or n==1:\n",
    "        word=next(iter(ngrams[0]))[0]#first key\n",
    "        a.append(word)\n",
    "        line=line+' '+word\n",
    "        # print(line)\n",
    "        get_n(n,a,line,word_limit-1)\n",
    "    elif sz<n-1:\n",
    "        found = False\n",
    "        for key in ngrams[sz]:\n",
    "            lis=list(key)\n",
    "            last_word=lis[-1]\n",
    "            lis=lis[:-1]\n",
    "            if lis==a:\n",
    "                line=line+' '+last_word\n",
    "                # a=a[1:]\n",
    "                a.append(last_word)\n",
    "                found=True\n",
    "                break\n",
    "        if found :\n",
    "            # print(line)\n",
    "            get_n(n,a,line,word_limit-1)\n",
    "        else : \n",
    "            print('Cant find')\n",
    "    elif sz==n-1:\n",
    "        found = False\n",
    "        for key in ngrams[n-1]:\n",
    "            lis=list(key)\n",
    "            last_word=lis[-1]\n",
    "            lis=lis[:-1]\n",
    "            if lis==a:\n",
    "                line=line+' '+last_word\n",
    "                a=a[1:]\n",
    "                a.append(last_word)\n",
    "                found=True\n",
    "                break\n",
    "        if found :\n",
    "            # print(line)\n",
    "            get_n(n,a,line,word_limit-1)\n",
    "        else : \n",
    "            print('Cant find')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(n,word_limit):\n",
    "    prev_tokens=[]\n",
    "    sentence=\"\"\n",
    "    line=get_n(n,prev_tokens,sentence,word_limit)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic harry pulled the door open and they ran inside hermione granger was shrinking against the wall opposite looking as if she was about to faint the troll was advancing on her knocking the sinks off the walls as it went confuse it harry said desperately to ron and seizing a tap he threw it as hard as he could into the kitchen harry hurried into the living room in time to catch the last report on the evening news and finally bird-watchers everywhere have reported that the nation s owls\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "filename='Harry_Potter_Text/'+'Book7.txt'\n",
    "with open(filename) as f:\n",
    "    Lines = f.readlines()\n",
    "    # book=\"\"\n",
    "    for lin in Lines:\n",
    "        if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "            if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "test_sentences=[]\n",
    "test_sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    test_sentences.append(li)\n",
    "    test_sentencewise_tokens.append(word_tokenize(li))\n",
    "test_tokens=word_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11138"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256058"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        test_final_tokens.append(token.strip('.'))\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204766"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vocab=set(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11449"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068\n"
     ]
    }
   ],
   "source": [
    "#OOV words\n",
    "unknum=len(test_vocab.difference(vocab))\n",
    "print(unknum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if token in vocab:\n",
    "        test_final_tokens.append(token)\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_book=' '.join(test_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and the door and the door and the\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21079"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            ratio=ngrams[0][tup]/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            ratio=ngrams[sz-1][tup1]/ngrams[sz-2][tup2]\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.579554625674844\n"
     ]
    }
   ],
   "source": [
    "s='the door and the door and the door and the'\n",
    "print(log_perp(2,s))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOOTHING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp1(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                ratio=(ngrams[0][tup]+1)/(len(tokens)+len(vocab))\n",
    "            else:\n",
    "                # ratio=(1)/(len(tokens)+len(vocab))\n",
    "                ratio=(1+unknum)/(len(tokens)+len(vocab)+len(test_vocab))\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                ratio=(ngrams[sz-1][tup1]+1)/(ngrams[sz-2][tup2]+len(ngrams[sz-2]))\n",
    "            elif tup2 in ngrams[sz-2]:\n",
    "                ratio=(1+unknum)/(ngrams[sz-2][tup2]+len(ngrams[sz-2])+len(test_vocab))\n",
    "            else:\n",
    "                ratio=(1+unknum)/(len(ngrams[sz-2])+len(test_vocab))\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with add-1 smoothing is 15.077224482717945\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with add-1 smoothing is',log_perp1(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with add-1 smoothing is 9.68405969187683\n",
      "Log2-perplexity for n = 2 with add-1 smoothing is 10.37694419347486\n",
      "Log2-perplexity for n = 3 with add-1 smoothing is 16.14611767521765\n",
      "Log2-perplexity for n = 4 with add-1 smoothing is 17.921149170446203\n",
      "Log2-perplexity for n = 5 with add-1 smoothing is 18.379349353423052\n"
     ]
    }
   ],
   "source": [
    "s=train_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with add-1 smoothing is',log_perp1(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with add-1 smoothing is 9.624973962147365\n",
      "Log2-perplexity for n = 2 with add-1 smoothing is 8.285671163168145\n",
      "Log2-perplexity for n = 3 with add-1 smoothing is 9.982676532703668\n",
      "Log2-perplexity for n = 4 with add-1 smoothing is 9.296837041067624\n",
      "Log2-perplexity for n = 5 with add-1 smoothing is 8.953607757258775\n"
     ]
    }
   ],
   "source": [
    "s=test_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with add-1 smoothing is',log_perp1(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOD TURING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_total=[] #holds total number of n gram tuples per n\n",
    "ngrams_freq=[]  #holds dictionary of frequency and count per n\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams_freq.append(d)\n",
    "for n in range (n_limit):\n",
    "    sum=0\n",
    "    for val in ngrams[n].values():\n",
    "        # print(val,n)\n",
    "        if val in ngrams_freq[n]:\n",
    "            ngrams_freq[n][val]=ngrams_freq[n][val]+1\n",
    "        else:\n",
    "            ngrams_freq[n][val]=1\n",
    "        sum+=val\n",
    "    ngrams_total.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_freq[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880933"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_freq[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp2(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                freq=ngrams[0][tup]\n",
    "                if freq+1 in ngrams_freq[0]:\n",
    "                    ratio=(freq+1)*ngrams_freq[0][freq+1]/(ngrams_freq[0][freq]*ngrams_total[0])\n",
    "                else:\n",
    "                    ratio=(freq+1)/(ngrams_freq[0][freq]*ngrams_total[0])\n",
    "            else:\n",
    "                if 1 in ngrams_freq[0]:\n",
    "                    ratio=ngrams_freq[0][1]/len(tokens)\n",
    "                else :\n",
    "                    ratio=1/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                freq=ngrams[sz-1][tup1]\n",
    "                if freq+1 in ngrams_freq[sz-1]:\n",
    "                    ratio=(freq+1)*ngrams_freq[sz-1][freq+1]/(ngrams_freq[sz-1][freq]*ngrams_total[sz-1])\n",
    "                else:\n",
    "                    ratio=(freq+1)/(ngrams_freq[sz-1][freq]*ngrams_total[sz-1])\n",
    "            else:\n",
    "                if 1 in ngrams_freq[sz-1]:\n",
    "                    #causing low pp\n",
    "                    ratio=ngrams_freq[sz-1][1]/ngrams_total[sz-1]\n",
    "                    # ratio=(len(sentences)/len(tokens))*ngrams_freq[sz-1][1]/ngrams_total[sz-1]\n",
    "                # if unknum+1 in ngrams_freq[sz-1]:\n",
    "                #     ratio=ngrams_freq[sz-1][1+unknum]/ngrams_total[sz-1]\n",
    "                else:\n",
    "                    ratio=1/ngrams_total[sz-1]\n",
    "            sum+=math.log2(ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with good turing smoothing is 18.961096391546445\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with good turing smoothing is',log_perp2(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with good turing smoothing is 9.799544830957888\n",
      "Log2-perplexity for n = 2 with good turing smoothing is 16.313882079917168\n",
      "Log2-perplexity for n = 3 with good turing smoothing is 20.19463759448822\n",
      "Log2-perplexity for n = 4 with good turing smoothing is 22.518577596490413\n",
      "Log2-perplexity for n = 5 with good turing smoothing is 24.181559692257593\n"
     ]
    }
   ],
   "source": [
    "s=train_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with good turing smoothing is',log_perp2(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with good turing smoothing is 9.699530164693511\n",
      "Log2-perplexity for n = 2 with good turing smoothing is 12.02172488585613\n",
      "Log2-perplexity for n = 3 with good turing smoothing is 6.9359015547532215\n",
      "Log2-perplexity for n = 4 with good turing smoothing is 2.4575399367718527\n",
      "Log2-perplexity for n = 5 with good turing smoothing is 0.7209077198811916\n"
     ]
    }
   ],
   "source": [
    "s=test_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with good turing smoothing is',log_perp2(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp3(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # print(sz)\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            ratio=ngrams[0][tup]/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                \n",
    "                lis=lis[:-1]\n",
    "                tup2=tuple(lis)\n",
    "                ratio=ngrams[sz-1][tup1]/ngrams[sz-2][tup2]\n",
    "                sum+=math.log2(ratio)\n",
    "            else :\n",
    "                lis=lis[1:]\n",
    "                snew=' '.join(lis)\n",
    "                back=-1*log_perp3(n-1,snew)*len(lis)\n",
    "                # print(snew,back)\n",
    "                sum+=back\n",
    "                sum+=math.log2(0.4)\n",
    "                \n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4733372813656676\n",
      "17.00506684057854\n",
      "11.400166108415785\n",
      "4.4733372813656676\n"
     ]
    }
   ],
   "source": [
    "print(log_perp(1,'the'))\n",
    "print(log_perp(1,'animagi'))\n",
    "print(log_perp3(2,'animagi the'))\n",
    "print(log_perp3(1,'the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_perp(2,'animagi the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with backoff smoothing is 1.9812421762636143\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with backoff smoothing is',log_perp3(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity with backoff smoothing is 7.710051297553377\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their ministry'\n",
    "n_val=5\n",
    "# print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with backoff smoothing is',log_perp3(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNESSER-NEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_unique_prefix=[]     # for each n gram model contains number of unique w_i-1 for each w_i as key\n",
    "ngrams_unique_suffix=[]     # for each n gram model contains number of unique w_i for each w_i-1 as key\n",
    "for i in range (n_limit):\n",
    "    d={}\n",
    "    ngrams_unique_prefix.append(d)\n",
    "    ngrams_unique_suffix.append(d)\n",
    "for n in range (1,n_limit):\n",
    "    for key in ngrams[n]:\n",
    "        lis=list(key)\n",
    "        lastword=lis[-1]\n",
    "        lis=tuple(lis[:-1])\n",
    "        if lastword in ngrams_unique_prefix[n]:\n",
    "            ngrams_unique_prefix[n][lastword]=ngrams_unique_prefix[n][lastword]+1\n",
    "        else:\n",
    "            ngrams_unique_prefix[n][lastword]=1\n",
    "        if lis in ngrams_unique_suffix[n]:\n",
    "            ngrams_unique_suffix[n][lis]=ngrams_unique_suffix[n][lis]+1\n",
    "        else:\n",
    "            ngrams_unique_suffix[n][lis]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp4(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        # Absolute discounting\n",
    "        if sz==1:\n",
    "            tup=tuple(lis)\n",
    "            if tup in ngrams[0]:\n",
    "                ratio=(ngrams[0][tup]-0.75)/len(tokens)\n",
    "            else :\n",
    "                ratio = 1/len(tokens)\n",
    "            sum+=math.log2(ratio)\n",
    "        else:\n",
    "            tup1=tuple(lis)\n",
    "            lis=lis[:-1]\n",
    "            tup2=tuple(lis)\n",
    "\n",
    "            # CONTINUATION PROBABILITY\n",
    "            lastword=lis[-1]\n",
    "            # pcont_ratio=0\n",
    "            pcont_ratio=ngrams_unique_prefix[sz-1][lastword]/len(ngrams[sz-1])\n",
    "\n",
    "            # LAMBDA\n",
    "            if tup2 in ngrams_unique_suffix[sz-1]:\n",
    "                lambdamult=0.75*ngrams_unique_suffix[sz-1][tup2]/ngrams[sz-2][tup2]\n",
    "            else: \n",
    "                lambdamult=1\n",
    "            # lambdamult=1\n",
    "\n",
    "            if tup1 in ngrams[sz-1]:\n",
    "                # add-1 smoothing\n",
    "                # ratio=(max(ngrams[sz-1][tup1]-0.75,0)+1)/(ngrams[sz-2][tup2]+ngrams[sz-2])\n",
    "                ratio=max(ngrams[sz-1][tup1]-0.75,0)/(ngrams[sz-2][tup2])\n",
    "                sum+=math.log2(ratio+lambdamult*pcont_ratio)\n",
    "            else :\n",
    "                ratio=1/len(ngrams[sz-2])\n",
    "                sum+=math.log2(ratio+lambdamult*pcont_ratio)\n",
    "\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity without smoothing is 1.9812421762636143\n",
      "Log2-perplexity with KN is 2.88767992295894\n"
     ]
    }
   ],
   "source": [
    "#comparison over generated sentences\n",
    "s='the door and turned the key fumbling in their panic'\n",
    "n_val=5\n",
    "print('Log2-perplexity without smoothing is',log_perp(n_val,s))\n",
    "print('Log2-perplexity with KN is',log_perp4(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with good turing smoothing is 9.713219375499346\n",
      "Log2-perplexity for n = 2 with good turing smoothing is 6.301462416452353\n",
      "Log2-perplexity for n = 3 with good turing smoothing is 3.9743021816536657\n",
      "Log2-perplexity for n = 4 with good turing smoothing is 2.6829447301356515\n",
      "Log2-perplexity for n = 5 with good turing smoothing is 2.291052087376773\n"
     ]
    }
   ],
   "source": [
    "s=train_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with good turing smoothing is',log_perp4(n_val,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity for n = 1 with good turing smoothing is 9.837587221150589\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'low-'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-43fa8e843e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_book\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Log2-perplexity for n ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'with good turing smoothing is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_perp4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-258-0e43a4f6d87e>\u001b[0m in \u001b[0;36mlog_perp4\u001b[0;34m(n, s)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mlastword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# pcont_ratio=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mpcont_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngrams_unique_prefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlastword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# LAMBDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'low-'"
     ]
    }
   ],
   "source": [
    "s=test_book\n",
    "for n_val in range(1,6):\n",
    "    print('Log2-perplexity for n =',n_val,'with good turing smoothing is',log_perp4(n_val,s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERPOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpy import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perp5(n,s):\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        \n",
    "        ratio_lis=[]\n",
    "        while True:\n",
    "            tup1=tuple(lis)\n",
    "            if len(lis)==1:\n",
    "                ratio=ngrams[0][tup1]/len(tokens)\n",
    "                ratio_lis.append(ratio)\n",
    "                break\n",
    "            elif tup1 in ngrams[len(lis)-1]:\n",
    "                lis2=lis[:-1]\n",
    "                tup2=tuple(lis2)\n",
    "                ratio=ngrams[len(lis)-1][tup1]/ngrams[len(lis)-2][tup2]\n",
    "                ratio_lis.append(ratio)\n",
    "            lis=lis[1:]\n",
    "        ratio_lis.reverse()\n",
    "        sz=len(ratio_lis)\n",
    "        final_ratio=0\n",
    "        for index in range(len(ratio_lis)):\n",
    "            final_ratio+=ratio_lis[index]*(1/sz)\n",
    "        sum+=math.log2(final_ratio)\n",
    "    return sum*(-1/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_perp5conv(n,s):\n",
    "    optszval=2\n",
    "    optlis=[]\n",
    "    for i in range(optszval):\n",
    "        optlis.append(1)\n",
    "    A=np.array(optlis)\n",
    "    words=s.split()\n",
    "    sum=0\n",
    "    for i in range(len(words)):\n",
    "        lis=[]\n",
    "        for j in range(i,i-n,-1):\n",
    "            if j>=0:\n",
    "                lis.append(words[j])\n",
    "        lis.reverse()\n",
    "        sz=len(lis)\n",
    "        \n",
    "        ratio_lis=[]\n",
    "        while True:\n",
    "            tup1=tuple(lis)\n",
    "            if len(lis)==1:\n",
    "                ratio=ngrams[0][tup1]/len(tokens)\n",
    "                ratio_lis.append(ratio)\n",
    "                break\n",
    "            elif tup1 in ngrams[len(lis)-1]:\n",
    "                lis2=lis[:-1]\n",
    "                tup2=tuple(lis2)\n",
    "                ratio=ngrams[len(lis)-1][tup1]/ngrams[len(lis)-2][tup2]\n",
    "                ratio_lis.append(ratio)\n",
    "            lis=lis[1:]\n",
    "        ratio_lis.reverse()\n",
    "        insz=len(ratio_lis)\n",
    "        while len(ratio_lis)<5:\n",
    "            ratio_lis.append(1)\n",
    "        # if insz==5:\n",
    "        nom=np.array(ratio_lis[:optszval])\n",
    "        A=np.vstack((A,nom)) \n",
    "\n",
    "        sz=len(ratio_lis)\n",
    "        final_ratio=0\n",
    "        for index in range(sz):\n",
    "            final_ratio+=ratio_lis[index]*(1/sz)\n",
    "        sum+=math.log2(final_ratio)\n",
    "    # print(A.shape)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the door and turned the key fumbling in their panic\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.916425467039723"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='the door and turned the key fumbling in their panic'\n",
    "log_perp5(5,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "filename='Harry_Potter_Text/'+'Book7.txt'\n",
    "with open(filename) as f:\n",
    "    Lines = f.readlines()\n",
    "    # book=\"\"\n",
    "    for lin in Lines:\n",
    "        if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "            if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "test_sentences=[]\n",
    "test_sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    # if not li[-1].isalnum():\n",
    "    #     li=li[:-1]\n",
    "    # li= '<s> '+li+' <e>'\n",
    "    test_sentences.append(li)\n",
    "    test_sentencewise_tokens.append(word_tokenize(li))\n",
    "test_tokens=word_tokenize(text)\n",
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        test_final_tokens.append(token.strip('.'))\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION\n",
    "\n",
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if token in tokens:\n",
    "        test_final_tokens.append(token)\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION\n",
    "\n",
    "test_book=' '.join(test_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEV SET OPTIMIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200656, 2)\n"
     ]
    }
   ],
   "source": [
    "s=test_book\n",
    "n_val=2\n",
    "A=log_perp5conv(n_val,s)\n",
    "A = np.delete(A, 0, 0)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison over generated sentences\n",
    "# s='the door and turned the key fumbling in their panic'\n",
    "# n_val=5\n",
    "# A=log_perp5conv(n_val,s)\n",
    "# A = np.delete(A, 0, 0)\n",
    "# print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.20349896e-02, 1.00000000e+00],\n",
       "       [4.50185287e-02, 3.60978251e-04],\n",
       "       [9.07973221e-04, 1.25934861e-02],\n",
       "       [3.20397249e-04, 1.49521531e-01],\n",
       "       [1.08609237e-06, 1.00000000e+00],\n",
       "       [4.50185287e-02, 1.00000000e+00],\n",
       "       [9.00370575e-04, 1.83353438e-03],\n",
       "       [4.01854177e-05, 3.61881785e-03],\n",
       "       [2.59576076e-04, 1.00000000e+00],\n",
       "       [3.95446232e-03, 5.85774059e-02],\n",
       "       [1.91619277e-02, 4.34221368e-01],\n",
       "       [4.23576024e-05, 9.63554951e-04],\n",
       "       [1.88904046e-02, 2.56410256e-02],\n",
       "       [6.22330928e-04, 2.67923877e-02],\n",
       "       [8.68873896e-06, 1.74520070e-03],\n",
       "       [1.18384068e-04, 1.25000000e-01],\n",
       "       [1.12975328e-02, 1.83486239e-02],\n",
       "       [4.50185287e-02, 2.80330706e-01],\n",
       "       [6.73377269e-05, 3.61881785e-04],\n",
       "       [6.51655422e-06, 1.00000000e+00]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cp.Variable(2)\n",
    "objective = cp.Maximize(sum(A @ x ))\n",
    "constraints = [0<= x, x <= 1, x[0]+x[1] == 1]\n",
    "prob = cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58419.45500736246\n"
     ]
    }
   ],
   "source": [
    "result = prob.solve()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.89995531e-10 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERFORMANCE ON DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "filename='Harry_Potter_Text/'+'Book7.txt'\n",
    "with open(filename) as f:\n",
    "    Lines = f.readlines()\n",
    "    # book=\"\"\n",
    "    for lin in Lines:\n",
    "        if not (len(lin)>5 and lin[:6]=='Page |'):\n",
    "            if lin != 'Harry Potter and the Goblet of Fire - J.K. Rowling \\n':\n",
    "                text+=lin.lower()\n",
    "x=sent_tokenize(text)\n",
    "test_sentences=[]\n",
    "test_sentencewise_tokens=[]\n",
    "for l in x:\n",
    "    li=''.join(l.splitlines())\n",
    "    # if not li[-1].isalnum():\n",
    "    #     li=li[:-1]\n",
    "    # li= '<s> '+li+' <e>'\n",
    "    test_sentences.append(li)\n",
    "    test_sentencewise_tokens.append(word_tokenize(li))\n",
    "test_tokens=word_tokenize(text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if not (len(token)==1 and not token.isalnum()):\n",
    "        test_final_tokens.append(token.strip('.'))\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204766"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_tokens=[]\n",
    "for token in test_tokens:\n",
    "    if token in vocab:\n",
    "        test_final_tokens.append(token)\n",
    "\n",
    "test_tokens=test_final_tokens\n",
    "#REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201487"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_book=' '.join(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2-perplexity by add-1 is 10.823696554299044\n",
      "Log2-perplexity by GT is 12.286189040700979\n",
      "Log2-perplexity by backoff is 7.88613436879754\n",
      "Log2-perplexity by KN is 7.6352386766761144\n",
      "Log2-perplexity by interpolation is 8.009244242918252\n"
     ]
    }
   ],
   "source": [
    "n_val=2\n",
    "print('Log2-perplexity by add-1 is',log_perp1(n_val,test_book))\n",
    "print('Log2-perplexity by GT is',log_perp2(n_val,test_book))\n",
    "print('Log2-perplexity by backoff is',log_perp3(n_val,test_book))\n",
    "print('Log2-perplexity by KN is',log_perp4(n_val,test_book))\n",
    "print('Log2-perplexity by interpolation is',log_perp5(n_val,test_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nval is  1\n",
      "Log2-perplexity by add-1 is 9.637674198640784\n",
      "Log2-perplexity by GT is 9.744650881479842\n",
      "Log2-perplexity by backoff is 9.63596637019401\n",
      "Log2-perplexity by KN is 9.674584457906617\n",
      "Log2-perplexity by interpolation is 8.635966370194161\n",
      "nval is  2\n",
      "Log2-perplexity by add-1 is 10.823696554299044\n",
      "Log2-perplexity by GT is 12.286189040700979\n",
      "Log2-perplexity by backoff is 7.88613436879754\n",
      "Log2-perplexity by KN is 7.6352386766761144\n",
      "Log2-perplexity by interpolation is 7.009244242918418\n",
      "nval is  3\n",
      "Log2-perplexity by add-1 is 17.070482445307025\n",
      "Log2-perplexity by GT is 7.093415573536828\n",
      "Log2-perplexity by backoff is 14.728368738314531\n",
      "Log2-perplexity by KN is 8.337810310178762\n",
      "Log2-perplexity by interpolation is 6.513892161228197\n",
      "nval is  4\n",
      "Log2-perplexity by add-1 is 19.070664509633033\n",
      "Log2-perplexity by GT is 2.5042689761335413\n",
      "Log2-perplexity by backoff is 31.78424852146726\n",
      "Log2-perplexity by KN is 9.128069518345992\n",
      "Log2-perplexity by interpolation is 6.401346299165748\n",
      "nval is  5\n",
      "Log2-perplexity by add-1 is 19.625265725557625\n",
      "Log2-perplexity by GT is 0.7335634888322755\n",
      "Log2-perplexity by backoff is 64.81466975491064\n",
      "Log2-perplexity by KN is 9.468328506993348\n",
      "Log2-perplexity by interpolation is 6.3825588383415015\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,n_limit+1):\n",
    "    n_val=n\n",
    "    print('nval is ',n)\n",
    "    print('Log2-perplexity by add-1 is',log_perp1(n_val,test_book))\n",
    "    print('Log2-perplexity by GT is',log_perp2(n_val,test_book))\n",
    "    print('Log2-perplexity by backoff is',log_perp3(n_val,test_book))\n",
    "    print('Log2-perplexity by KN is',log_perp4(n_val,test_book))\n",
    "    print('Log2-perplexity by interpolation is',log_perp5(n_val,test_book))\n",
    "    # print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a9832322fafd2730dc149af687337c0a09b45fcc0b3b65c4fba6625a2f98152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
